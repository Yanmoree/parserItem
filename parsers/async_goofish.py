# parsers/async_goofish.py - Ð°ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð¿Ð°Ñ€ÑÐµÑ€ Ð´Ð»Ñ ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°
import aiohttp
import asyncio
import aiofiles
import json
import hashlib
import time
import random
from typing import List, Dict, Optional, Tuple
import logging

from models import Product
from config import (
    GOOFISH_COOKIES_FILE, ROWS_PER_PAGE, 
    REQUEST_TIMEOUT, DEFAULT_USER_AGENT,
    MAX_RETRIES, REQUEST_DELAY_MIN, REQUEST_DELAY_MAX, 
    RATE_LIMIT_DELAY, MAX_REQUESTS_PER_HOUR
)
from storage.files import load_seen_ids, add_seen_ids

logger = logging.getLogger(__name__)

class AsyncGoofishParser:
    """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð¿Ð°Ñ€ÑÐµÑ€ Ð´Ð»Ñ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²"""
    
    def __init__(self, cookies_file=None):
        self.cookies_file = cookies_file or GOOFISH_COOKIES_FILE
        self.cookies = None
        self.session = None
        self.seen_ids = set()
        self.semaphore = asyncio.Semaphore(3)  # ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ 3 Ð¾Ð´Ð½Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        self.request_count = 0
        self.success_count = 0
        
    async def initialize(self):
        """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ"""
        self.cookies = await self._load_cookies()
        self.seen_ids = load_seen_ids()
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐµÑÑÐ¸ÑŽ aiohttp
        self.session = aiohttp.ClientSession(
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Referer': 'https://www.goofish.com/',
                'Accept': 'application/json',
            },
            cookie_jar=aiohttp.CookieJar()
        )
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ cookies
        if self.cookies:
            for name, value in self.cookies.items():
                self.session.cookie_jar.update_cookies({name: value})
        
        logger.info(f"ðŸ”„ ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð¿Ð°Ñ€ÑÐµÑ€ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½")
    
    async def _load_cookies(self) -> Dict:
        """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° cookies"""
        try:
            async with aiofiles.open(self.cookies_file, 'r', encoding='utf-8') as f:
                content = await f.read()
                cookies = json.loads(content)
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ cookies
            required = ['_m_h5_tk', 't', 'cookie2']
            for req in required:
                if req not in cookies:
                    logger.error(f"âŒ ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ cookie: {req}")
                    return {}
            
            return cookies
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ cookies: {e}")
            return {}
    
    async def _make_async_request(self, query: str, page: int, rows: int = 20) -> Optional[Dict]:
        """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ñ ÑÐµÐ¼Ð°Ñ„Ð¾Ñ€Ð¾Ð¼"""
        async with self.semaphore:
            self.request_count += 1
            
            # Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°
            delay = random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX)
            logger.debug(f"â³ Ð—Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð´Ð»Ñ '{query}': {delay:.1f} ÑÐµÐº")
            await asyncio.sleep(delay)
            
            for attempt in range(MAX_RETRIES):
                try:
                    if attempt > 0:
                        retry_delay = 5 * (attempt + 1)
                        logger.info(f"   â†» ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€ {attempt + 1} Ð´Ð»Ñ '{query}'. Ð–Ð´ÐµÐ¼ {retry_delay:.1f} ÑÐµÐº")
                        await asyncio.sleep(retry_delay)
                    
                    # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
                    token_full = self.cookies.get('_m_h5_tk', '')
                    if not token_full or '_' not in token_full:
                        logger.error("âŒ Ð¢Ð¾ÐºÐµÐ½ Ð½ÐµÐ²Ð°Ð»Ð¸Ð´ÐµÐ½")
                        return None
                    
                    token, token_timestamp = token_full.split('_', 1)
                    
                    data_dict = {
                        "pageNumber": page,
                        "keyword": query,
                        "rowsPerPage": rows,
                        "sortValue": "new",
                    }
                    
                    data_str = json.dumps(data_dict, separators=(',', ':'))
                    
                    # ÐŸÐ¾Ð´Ð¿Ð¸ÑÑŒ
                    sign_string = f"{token}&{token_timestamp}&34839810&{data_str}"
                    signature = hashlib.md5(sign_string.encode()).hexdigest()
                    
                    # ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹
                    params = {
                        'jsv': '2.7.2',
                        'appKey': '34839810',
                        't': token_timestamp,
                        'sign': signature,
                        'api': 'mtop.taobao.idlemtopsearch.pc.search',
                        'v': '1.0',
                        'type': 'json',
                        'dataType': 'json',
                        'data': data_str
                    }
                    
                    logger.info(f"ðŸ“¨ ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ: '{query}', ÑÑ‚Ñ€. {page}")
                    
                    async with self.session.post(
                        "https://h5api.m.goofish.com/h5/mtop.taobao.idlemtopsearch.pc.search/1.0/",
                        params=params,
                        timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT)
                    ) as response:
                        
                        if response.status == 200:
                            result = await response.json()
                            
                            if 'ret' in result:
                                ret_val = result['ret']
                                if isinstance(ret_val, list) and len(ret_val) > 0:
                                    ret_str = ret_val[0]
                                    
                                    if 'SUCCESS' in ret_str:
                                        self.success_count += 1
                                        logger.info(f"âœ… Ð£ÑÐ¿ÐµÑ… Ð´Ð»Ñ '{query}'")
                                        return result
                                    
                                    elif 'RGV587_ERROR' in ret_str:
                                        logger.warning(f"ðŸš« Rate limit Ð´Ð»Ñ '{query}'")
                                        await asyncio.sleep(RATE_LIMIT_DELAY)
                                        continue
                            
                            return result
                        
                        elif response.status == 429:
                            logger.error(f"âŒ 429 Ð´Ð»Ñ '{query}'")
                            await asyncio.sleep(RATE_LIMIT_DELAY)
                            continue
                        
                        else:
                            logger.error(f"âŒ HTTP {response.status} Ð´Ð»Ñ '{query}'")
                            await asyncio.sleep(10)
                
                except asyncio.TimeoutError:
                    logger.error(f"â±ï¸ Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð´Ð»Ñ '{query}' (Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ° {attempt + 1})")
                    await asyncio.sleep(15)
                
                except Exception as e:
                    logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð´Ð»Ñ '{query}': {e}")
                    await asyncio.sleep(10)
            
            logger.error(f"ðŸ”¥ Ð’ÑÐµ Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ¸ Ð¸ÑÑ‡ÐµÑ€Ð¿Ð°Ð½Ñ‹ Ð´Ð»Ñ '{query}'")
            return None
    
    async def search_async(self, query: str, page: int = 1, rows: int = 20) -> List[Product]:
        """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº"""
        logger.info(f"ðŸ” ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº: '{query}', ÑÑ‚Ñ€. {page}")
        
        response = await self._make_async_request(query, page, rows)
        if not response:
            return []
        
        products = self._parse_response_simple(response, query)
        new_products = [p for p in products if p.id not in self.seen_ids]
        
        if new_products:
            new_ids = [p.id for p in new_products]
            add_seen_ids(new_ids)
        
        logger.info(f"   âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð¾: {len(products)}, Ð½Ð¾Ð²Ñ‹Ñ…: {len(new_products)}")
        return new_products
    
    def _parse_response_simple(self, api_response: Dict, query: str) -> List[Product]:
        """Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³ (Ð¼Ð¾Ð¶Ð½Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ð±Ñ‰Ð¸Ð¹)"""
        products = []
        
        if not api_response:
            return products
        
        data = api_response.get('data', {})
        result_list = data.get('resultList', [])
        
        for item in result_list[:15]:  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼
            try:
                item_data = item.get('data', {}).get('item', {})
                if not item_data:
                    continue
                
                main_data = item_data.get('main', {})
                args = main_data.get('clickParam', {}).get('args', {})
                
                if not args:
                    continue
                
                item_id = args.get('id', '')
                title = args.get('title', '')[:100]
                price_str = args.get('price', '0')
                
                try:
                    price_str = price_str.replace('Â¥', '').replace('ï¿¥', '').strip()
                    price_yuan = float(price_str)
                except:
                    price_yuan = 0
                
                if not item_id or not title:
                    continue
                
                product = Product(
                    id=item_id,
                    title=title,
                    price_yuan=price_yuan,
                    url=f"https://www.goofish.com/item?id={item_id}",
                    location=args.get('area', ''),
                    age_minutes=0,
                    query=query,
                    images=[],
                    is_original=False
                )
                
                products.append(product)
                
            except Exception as e:
                continue
        
        return products
    
    async def search_multiple_queries(self, queries: List[str], max_pages: int = 1) -> Dict[str, List[Product]]:
        """ÐŸÐ°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð¿Ð¾ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ð¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼"""
        results = {}
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð´Ð»Ñ Ð²ÑÐµÑ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
        tasks = []
        for query in queries:
            for page in range(1, max_pages + 1):
                task = self.search_async(query, page)
                tasks.append(task)
        
        # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð²ÑÐµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾
        all_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
        task_idx = 0
        for query in queries:
            query_results = []
            for page in range(1, max_pages + 1):
                result = all_results[task_idx]
                task_idx += 1
                
                if isinstance(result, Exception):
                    logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð´Ð»Ñ '{query}' ÑÑ‚Ñ€. {page}: {result}")
                elif result:
                    query_results.extend(result)
            
            if query_results:
                results[query] = query_results
        
        return results
    
    async def close(self):
        """Ð—Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ ÑÐµÑÑÐ¸Ð¸"""
        if self.session:
            await self.session.close()
    
    def get_stats(self) -> Dict:
        """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°"""
        success_rate = (self.success_count / self.request_count * 100) if self.request_count > 0 else 0
        
        return {
            'total_requests': self.request_count,
            'successful_requests': self.success_count,
            'success_rate': round(success_rate, 1),
            'active_sessions': self.semaphore._value if self.semaphore else 0,
        }